{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacion de imagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os.path\n",
    "import glob\n",
    "import torch\n",
    "import architecture as arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bImg = cv2.imread(\"arbol3.jpg\")\n",
    "overlayImage_tortuga = cv2.imread(\"tortuga_png1.png\" , cv2.IMREAD_UNCHANGED)\n",
    "overlayImage_conejo = cv2.imread(\"liebre1.png\" , cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mantener el aspecto de la tasa de la imagen original\n",
    "Cambia el tamaño sin distorsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arbol = image_resize(bImg, height = 200)\n",
    "overlayImage_tortuga = image_resize(overlayImage_tortuga, height = 40)\n",
    "overlayImage_conejo = image_resize(overlayImage_conejo, height = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transparentOverlay(src , overlay , pos=(0,0),scale = 1):\n",
    "\n",
    "    overlay = cv2.resize(overlay,(0,0),fx=scale,fy=scale)\n",
    "\n",
    "    h,w,_ = overlay.shape  # Size of foreground\n",
    "\n",
    "    rows,cols,_ = src.shape  # Size of background Image\n",
    "\n",
    "    y,x = pos[0],pos[1]    # Position of foreground/overlay image\n",
    "\n",
    "\n",
    "    for i in range(h):\n",
    "\n",
    "        for j in range(w):\n",
    "\n",
    "            if x+i >= rows or y+j >= cols:\n",
    "\n",
    "                continue\n",
    "\n",
    "            alpha = float(overlay[i][j][3]/255.0) # read the alpha channel \n",
    "\n",
    "            src[x+i][y+j] = alpha*overlay[i][j][:3]+(1-alpha)*src[x+i][y+j]\n",
    "\n",
    "    return src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = transparentOverlay(image_arbol,overlayImage_tortuga,(55,155),1)\n",
    "result2 = transparentOverlay(result,overlayImage_conejo,(130,145),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path ='./models/RRDB_ESRGAN_x4.pth'#sys.argv[1]  # models/RRDB_ESRGAN_x4.pth OR models/RRDB_PSNR_x4.pth\n",
    "#device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n",
    "device = torch.device('cpu')\n",
    "\n",
    "test_img_folder = 'LR/*'\n",
    "\n",
    "model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=4, norm_type=None, act_type='leakyrelu', \\\n",
    "                        mode='CNA', res_scale=1, upsample_mode='upconv')\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "img = result2 * 1.0 / 255\n",
    "img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "img_LR = img.unsqueeze(0)\n",
    "img_LR = img_LR.to(device)\n",
    "\n",
    "output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "output = (output * 255.0).round()\n",
    "cv2.imwrite('rsgan.png',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecualización de Histograma en Python\n",
    "Mejora el contraste de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('rsgan.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_yuv = cv2.cvtColor(img,cv2.COLOR_BGR2YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_yuv[:,:,0] = cv2.equalizeHist(img_to_yuv[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_equalization_result = cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrado de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_equ = cv2.GaussianBlur(hist_equalization_result,(3,3),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize de la imagen resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_final = image_resize(blur_equ, height = 350)\n",
    "cv2.imwrite('Collage_animalibro_final.jpg',image_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
